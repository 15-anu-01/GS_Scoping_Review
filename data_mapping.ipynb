{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b05106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "\n",
    "bedrock = boto3.client('bedrock-runtime', region_name = 'us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d835f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"D:/GS/final_scoping_review/data_extractions/stage3_health_theme/2023_2024.xlsx\"\n",
    "\n",
    "df_terms = pd.read_excel(\"D:/GS/final_scoping_review/shortened_sub_health_themes.xlsx\")\n",
    "df_docs = pd.read_excel(\"D:/GS/final_scoping_review/final_excels/yearly_grouped_excels/2023_2024.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d00b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3823/3823\n",
      "Batch processing complete! Results saved to final_sub_theme_short_mapping.xlsx\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 1. Batch Processing Function\n",
    "########################################\n",
    "def batch_check_relevance(terms_definitions, abstract, max_retries=3):\n",
    "    \"\"\"\n",
    "    Processes all terms for one document in a single API call\n",
    "    Returns list of relevant terms or empty list on failure\n",
    "    \"\"\"\n",
    "    # Truncate abstract to save tokens (adjust as needed)\n",
    "    # truncated_abstract = abstract[:1500] + \"...\" if len(abstract) > 1500 else abstract\n",
    "    truncated_abstract = abstract\n",
    "    \n",
    "    # Create term-definition list with numbering\n",
    "    numbered_terms = \"\\n\".join([f\"{i+1}. {term}: {defn}\" \n",
    "                              for i, (term, defn) in enumerate(terms_definitions.items())])\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this abstract and return COMMA-SEPARATED list of relevant term which best describes the abstract based on the term's definitions (NUMBERS ONLY):\n",
    "    \n",
    "Terms/Definitions:\n",
    "{numbered_terms}\n",
    "\n",
    "Abstract: {truncated_abstract}\n",
    "\n",
    "Return ONLY comma-separated numbers of relevant terms \n",
    "If none are relevant, return \"0\". Do not include explanations.\"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}]\n",
    "        }]\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock.invoke_model(\n",
    "                body=json.dumps(payload),\n",
    "                modelId='anthropic.claude-3-5-sonnet-20240620-v1:0',  # Cheaper model\n",
    "                accept='application/json',\n",
    "                contentType='application/json'\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response['body'].read().decode('utf-8'))\n",
    "            response_text = result['content'][0]['text'].strip()\n",
    "            \n",
    "            if response_text == \"0\":\n",
    "                return []\n",
    "                \n",
    "            # Convert number responses back to term names\n",
    "            term_numbers = [int(n) for n in response_text.split(\",\")]\n",
    "            term_list = list(terms_definitions.keys())\n",
    "            return [term_list[n-1] for n in term_numbers if 0 < n <= len(term_list)]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    return []  # Return empty if all retries fail\n",
    "\n",
    "########################################\n",
    "# 2. Main Script with Optimizations\n",
    "########################################\n",
    "\n",
    "# Preprocess terms into a dictionary\n",
    "terms_dict = dict(zip(df_terms['Term'], df_terms['Shortened_Definition']))\n",
    "\n",
    "mapped_results = []\n",
    "total_docs = len(df_docs)\n",
    "\n",
    "for i, doc_row in df_docs.iterrows():\n",
    "    doc_title = doc_row['Title']\n",
    "    doc_abstract = doc_row['Abstract']\n",
    "    \n",
    "    # Get relevant terms in batch\n",
    "    relevant_terms = batch_check_relevance(terms_dict, doc_abstract)\n",
    "    \n",
    "    # Filter valid terms\n",
    "    valid_terms = [term for term in relevant_terms if term in terms_dict]\n",
    "    \n",
    "    mapped_results.append({\n",
    "        \"Title\": doc_title,\n",
    "        \"Relevant Terms\": \", \".join(valid_terms)\n",
    "    })\n",
    "    \n",
    "    # Progress tracking with flush\n",
    "    print(f\"Processed {i+1}/{total_docs}\", end='\\r', flush=True)\n",
    "\n",
    "# Save results\n",
    "output_df = pd.DataFrame(mapped_results)\n",
    "output_df.to_excel(output, index=False)\n",
    "\n",
    "print(\"\\nBatch processing complete! Results saved to final_sub_theme_short_mapping.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c79523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
